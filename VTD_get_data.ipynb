{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sporting-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from QualtricsAPI.Setup import Credentials\n",
    "from QualtricsAPI.Survey import Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a92251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19096485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==1.4.3\n",
      "numpy==1.22.3\n"
     ]
    }
   ],
   "source": [
    "# versions\n",
    "\n",
    "print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b04b41",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83e18fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data through API and anonymize\n",
    "\n",
    "qtoken = '...' # personal token, can get this from qualtrics\n",
    "qdc = '...' # country where the data is stored -- can find this in your qualtrics account\n",
    "s_id = '...' # survey id, can find this in qualtrics account\n",
    "\n",
    "Credentials().qualtrics_api_credentials(token=qtoken,data_center=qdc)\n",
    "df = Responses().get_survey_responses(survey=s_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b24ef756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store questions and drop survey information rows\n",
    "\n",
    "questions = df.iloc[0]\n",
    "df = df.iloc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2852a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only responses after survey was sent out to participants\n",
    "\n",
    "df['start'] = pd.to_datetime(df['StartDate'])\n",
    "df['end'] = pd.to_datetime(df['EndDate']) \n",
    "df = df.loc[(df['start'] > \"2022-09-15\") & (df['end'] < \"2022-11-14\")]\n",
    "\n",
    "# column to indicate if a response is part of the registered dataset\n",
    "df['main_data'] = np.where(df['end'] < \"2022-10-16\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f82f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export raw data for upload\n",
    "\n",
    "# make a copy and add the question descriptions\n",
    "\n",
    "df_raw = df.copy()\n",
    "a = pd.Series(['startdate','enddate','main_data'])\n",
    "questions = pd.concat([questions,a])\n",
    "df_raw.iloc[0] = questions\n",
    "\n",
    "# remove columns to safeguard anonimity: countries and comments removed\n",
    "\n",
    "df_raw.drop(columns = ['D3','Q41'])\n",
    "\n",
    "# save\n",
    "\n",
    "df_raw.to_csv(r'...', sep = ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb8ab6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "\n",
    "df = df.rename(columns = {'Duration (in seconds)': 'duration', 'D1': 'taxonomist?','D2':'professional','D3':'Country',\n",
    "                         'D4': 'specialization', 'D5': 'broad_reader', 'D6': 'experience'})\n",
    "df.duration = df.duration.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0755a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of responses that took less than 180 secs (and are dropped): 106\n"
     ]
    }
   ],
   "source": [
    "# remove responses that took less than 180 secs (as preregistered)\n",
    "\n",
    "print(f'number of responses that took less than 180 secs (and are dropped): {len(df.loc[(df.duration < 180)])}')\n",
    "df = df.loc[(df.duration > 150)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b127b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    456\n",
       "2     97\n",
       "Name: taxonomist?, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['taxonomist?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a27d03",
   "metadata": {},
   "source": [
    "# Variables, categories etc we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "187df3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = ['taxonomist?', 'professional',\n",
    "       'Country', 'specialization', 'broad_reader', 'experience', 'species_concepts']\n",
    "agree = ['c1_agree', 'c2_agree','c3_agree']\n",
    "accept = ['c1_accept','c2_accept','c3_accept']\n",
    "cases = ['condition_c1','condition_c2','condition_c3']\n",
    "demo2 = ['taxonomist?','professional','specialization','broad_reader','experience','species_concepts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3e99235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column for condition for case1\n",
    "\n",
    "df['condition_c1'] =  np.where(\n",
    "    df['1A_Agree'].notnull(), 'Neutral', np.where(\n",
    "    df['1B_Agree'].notnull(), 'Threatened', np.where(\n",
    "    df['1C_Agree'].notnull(), 'Abundant', 'No response')) )\n",
    "\n",
    "#create shared columns for case 1 agree \n",
    "\n",
    "df['c1_agree'] = np.where(\n",
    "    df['condition_c1'] == 'Neutral', df['1A_Agree'], np.where(\n",
    "    df['condition_c1'] == 'Threatened', df['1B_Agree'], np.where(\n",
    "    df['condition_c1'] == 'Abundant', df['1C_Agree'], 'No response')) )\n",
    "\n",
    "#create shared columns for case 1 accept\n",
    "\n",
    "df['c1_accept'] = np.where(\n",
    "    df['condition_c1'] == 'Neutral', df['1A_Accept'], np.where(\n",
    "    df['condition_c1'] == 'Threatened', df['1B_accept'], np.where(\n",
    "    df['condition_c1'] == 'Abundant', df['1C_Accept'], 'No response')) )\n",
    "\n",
    "\n",
    "#create column for condition for case2\n",
    "\n",
    "df['condition_c2'] =  np.where(\n",
    "    df['2A_Agree'].notnull(), 'Neutral',  np.where(\n",
    "    df['2C_Agree'].notnull(), 'Morphology', np.where(\n",
    "    df['2D_Agree'].notnull(), 'DNA', np.where(\n",
    "    df['2E_Agree'].notnull(), 'Habitat', 'No response')))) \n",
    "\n",
    "#create shared columns for case 2 agree \n",
    "\n",
    "df['c2_agree'] =  np.where(\n",
    "    df['condition_c2']== 'Neutral', df['2A_Agree'],  np.where(\n",
    "    df['condition_c2']== 'Morphology', df['2C_Agree'], np.where(\n",
    "    df['condition_c2']== 'DNA', df['2D_Agree'], np.where(\n",
    "    df['condition_c2']== 'Habitat', df['2E_Agree'], 'No response')))) \n",
    "\n",
    "#create shared columns for case 2 accept\n",
    "\n",
    "df['c2_accept'] =  np.where(\n",
    "    df['condition_c2']== 'Neutral', df['2A_Accept'],  np.where(\n",
    "    df['condition_c2']== 'Morphology', df['2C_Accept'], np.where(\n",
    "    df['condition_c2']== 'DNA', df['2D_Accept'], np.where(\n",
    "    df['condition_c2']== 'Habitat', df['2E_Accept'], 'No response')))) \n",
    "\n",
    "\n",
    "#create shared columns for case 2 lacking\n",
    "\n",
    "df['c2_lack_morph'] =  np.where(\n",
    "    df['condition_c2']== 'Neutral', df['2A_Lack_2'],   np.where(\n",
    "    df['condition_c2']== 'DNA', df['2D_Lack_1'], np.where(\n",
    "    df['condition_c2']== 'Habitat', df['2E_Lack_1'], 0)))\n",
    "\n",
    "df['c2_lack_dna'] =  np.where(\n",
    "    df['condition_c2']== 'Neutral', df['2A_Lack_3'],  np.where(\n",
    "    df['condition_c2']== 'Morphology', df['2C_Lack_2'],  np.where(\n",
    "    df['condition_c2']== 'Habitat', df['2E_Lack_2'],0)))\n",
    "\n",
    "df['c2_lack_hab'] =  np.where(\n",
    "    df['condition_c2']== 'Neutral', df['2A_Lack_4'],  np.where(\n",
    "    df['condition_c2']== 'Morphology', df['2C_Lack_3'], np.where(\n",
    "    df['condition_c2']== 'DNA', df['2D_Lack_3'], 0))) \n",
    "\n",
    "df['c2_lack_other'] =  np.where(\n",
    "    df['condition_c2']== 'Neutral', df['2A_Lack_5_TEXT'],  np.where(\n",
    "    df['condition_c2']== 'Morphology', df['2C_Lack_4_TEXT'], np.where(\n",
    "    df['condition_c2']== 'DNA', df['2D_Lack_4_TEXT'], np.where(\n",
    "    df['condition_c2']== 'Habitat', df['2E_Lack_4_TEXT'], 0))) )\n",
    "\n",
    "#create column for condition for case3\n",
    "\n",
    "df['condition_c3'] =  np.where(\n",
    "    df['3A_Agree'].notnull(), 'Neutral', np.where(\n",
    "    df['3B_Agree'].notnull(), 'No gene flow', np.where(\n",
    "    df['3C_Agree'].notnull(), 'Gene flow', 'No response')) )\n",
    "\n",
    "#create shared columns for case 3 agree \n",
    "\n",
    "df['c3_agree'] = np.where(\n",
    "    df['condition_c3'] == 'Neutral', df['3A_Agree'], np.where(\n",
    "    df['condition_c3'] == 'No gene flow', df['3B_Agree'], np.where(\n",
    "    df['condition_c3'] == 'Gene flow', df['3C_Agree'], 'No response')) )\n",
    "\n",
    "#create shared columns for case 3 accept\n",
    "\n",
    "df['c3_accept'] = np.where(\n",
    "    df['condition_c3'] == 'Neutral', df['3A_Accept'], np.where(\n",
    "    df['condition_c3'] == 'No gene flow', df['3B_Accept'], np.where(\n",
    "    df['condition_c3'] == 'Gene flow', df['3C_Accept'], 'No response')) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "670dbad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change '1 and '2' into 'yes' and 'no'\n",
    "\n",
    "df[agree+accept] = df[agree+accept].replace({'1':'yes','2':'no'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a723aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get meaningful values for demo questions\n",
    "\n",
    "df['professional'].replace({'1': 'pro','3':'amateur'}, inplace = True)\n",
    "df['taxonomist?'].replace({'1': 'taxonomist','2':'non_taxonomist'}, inplace = True)\n",
    "df['broad_reader'].replace({'1': 'never','2':'rarely','3':'once in a while','4':'regularly','5':'very often'}, inplace = True)\n",
    "df['specialization'].replace({'1': 'Mammals','2':'Birds','3':'Reptiles and Amphibia','4':'Fish','5':'Non-vertebrate Deuterostomes',\n",
    "                         '6':'Insects','7':'Non-insect Arthropods', '8':'Molluscs','9':'Remaining invertebrates',\n",
    "                         '14':'Algae','10':'Protists (non-algae)','11':'Plants','12':'Fungi','13':'Prokaryotes'}, inplace = True)\n",
    "df['experience'].replace({'1': '0-5','2':'6-10','3':'11-20','4':'21-30','5':'31+'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dd7692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn experience into an ordered categorical\n",
    "\n",
    "df.experience.fillna('No response')\n",
    "cat_type = pd.CategoricalDtype( categories = ['0-5','6-10', '11-20', '21-30', '31+','No response' ], ordered=True)\n",
    "df['experience'] = df['experience'].astype(cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e6d5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change values for the 'species concept' question into meaningful phrases\n",
    "\n",
    "df['species_concepts'] = df['D7'].replace({'1':'BSC', '2':'ESC', '3':'GCSP', '4': 'PSCdia','5': 'PSCmono', '6': 'other'})\n",
    "\n",
    "df['SC_full'] = np.where(\n",
    "    df['species_concepts'].notnull(), df['species_concepts'], np.where(\n",
    "    df['D7_6_TEXT'] == 'other', df['D7_6_TEXT'],  'No response'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777a450",
   "metadata": {},
   "source": [
    "georgia = europe\n",
    "azeirbejan = asia\n",
    "armenia = asia\n",
    "cyprus = europe\n",
    "turkey = europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4769074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace country codes by names, and add country classifications (continent, least developed, low income)\n",
    "# note: country level-data will not be uploaded \n",
    "\n",
    "# list of countries from world bank\n",
    "countries = pd.read_csv(r'...', sep = ';')\n",
    "countries = countries.iloc[1:,:].copy()\n",
    "\n",
    "countries.high_income_OECD.fillna(1, inplace = True)\n",
    "countries.UN_least_developed.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "countries.columns = ['country','code', 'low_income', 'least_developed','continent']\n",
    "a = dict(zip(countries.code,countries.country))\n",
    "b = dict(zip(countries.country, countries.continent))\n",
    "c = dict(zip(countries.country, countries.least_developed))\n",
    "d = dict(zip(countries.country, countries.low_income))\n",
    "\n",
    "df.Country.fillna('No response', inplace = True)\n",
    "df.Country = df.Country.replace(a)\n",
    "\n",
    "df['continent'] = list(df.Country)\n",
    "\n",
    "df['least_developed'] = df['continent'].replace(c)\n",
    "df['low_income'] = df['continent'].replace(d)\n",
    "df['continent'] = df['continent'].replace(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33e39015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that we don't need\n",
    "\n",
    "df = df.drop(columns=['StartDate', 'EndDate','RecordedDate', 'Progress','ResponseId','DistributionChannel',\n",
    "       'UserLanguage','1A_Agree',\n",
    "       '1A_Accept', '1B_Agree', '1B_accept', '1C_Agree', '1C_Accept',\n",
    "       '2A_Agree', '2A_Lack_2', '2A_Lack_3', '2A_Lack_4', '2A_Lack_5',\n",
    "       '2A_Lack_5_TEXT', '2A_Accept', '2C_Agree', '2C_Lack_2', '2C_Lack_3',\n",
    "       '2C_Lack_4', '2C_Lack_4_TEXT', '2C_Accept', '2D_Agree', '2D_Lack_1',\n",
    "       '2D_Lack_3', '2D_Lack_4', '2D_Lack_4_TEXT', '2D_Accept', '2E_Agree',\n",
    "       '2E_Lack_1', '2E_Lack_2', '2E_Lack_4', '2E_Lack_4_TEXT', '2E_Accept',\n",
    "       '3A_Agree', '3A_Accept', '3B_Agree', '3B_Accept', '3C_Agree',\n",
    "       '3C_Accept', 'D7', 'D7_6_TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0a4237e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581, 32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d573bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    581\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicate rows\n",
    "\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b34e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the df for use in other notebooks and for upload\n",
    "\n",
    "df.to_csv(r'...', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
